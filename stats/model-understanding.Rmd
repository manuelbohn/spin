---
title: "model-understanding"
author: "MH Tessler"
date: "5/4/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Breaking down the model, for understanding

## Model utilities

```{r}
library(tidyverse)
library(rwebppl)
library(brms)
library(coda)
library(ggthemes)
library(readxl)
library(ggpubr)
library(stringr)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}


hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}

me_data <- read_csv("../data/child_basic_me.csv")

```

## RSA model

```{r rsaUtils}
rsaUtils <- '
var all_objects = [
{ shape: "novel_object"},  
{ shape: "familiar_object"}
]

var labels = ["novel_word","familiar_word"]


var lexicon1 = function(utterance, obj, sem_knowledge){
utterance.label == "novel_word" ? obj.shape == "novel_object" :
utterance.label == "familiar_word" ? flip(sem_knowledge) ? obj.shape == "familiar_object" :  obj.shape == "novel_object" : 
true
}

var lexicon2 = function(utterance, obj, sem_knowledge){
utterance.label == "novel_word" ? obj.shape == "familiar_object" :
utterance.label == "familiar_word" ? flip(sem_knowledge) ? obj.shape == "familiar_object" :  obj.shape == "novel_object" : 
true
}

var lexiconObjects = {
"novel_word = novel_object": {
novel_object: "novel_word", familiar_object: "familiar_word"
},
"novel_word = familiar_object": {
novel_object: "familiar_word", familiar_object: "familiar_word"
},
}

var lexiconObject = {
"novel_word = novel_object": lexicon1,
"novel_word = familiar_object" : lexicon2
}

var utterancePrior = function(){ return uniformDraw([ {label: "novel_word"}, {label: "familiar_word"}]) }

var LexiconPrior = Categorical({vs: ["novel_word = novel_object","novel_word = familiar_object" ], ps: [1, 1]})

var foreach = function(fn, lst) {
    var foreach_ = function(i) {
        if (i < lst.length) {
            fn(lst[i]);
            foreach_(i + 1);
        }
    };
    foreach_(0);
};


var logistic = function(x) {1 / (1 + Math.exp(-x))}

var levels = function(df, label){
  return _.uniq(_.map(df, label));
}
'
```

```{r rsa model}
rsaModel <- '
var literalListener = cache(function(utterance, priorProbs, sem_knowledge){
  Infer({method: "enumerate", model: function(){
    var lexiconName = sample(LexiconPrior); 
    var lexicon = lexiconObject[lexiconName];
    var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
    if ("label" in utterance) {
      var truthValue = lexicon(utterance, obj, sem_knowledge);
      condition(truthValue)
    }
    return obj.shape 
  }})
}, 10000)

var speaker = cache(function(obj, lexiconName, priorProbs, speakerOptimality, sem_knowledge){
  Infer({method: "enumerate", model: function(){
    var utterance = utterancePrior();
    var L0 = literalListener(utterance, priorProbs, sem_knowledge);
    factor(speakerOptimality * L0.score(obj.shape))
    return utterance
  }})
}, 10000)

var pragmaticListener = cache(function(utterance, priorProbs, speakerOptimality, sem_knowledge){
  Infer({method: "enumerate", model: function(){
    var lexiconName = sample(LexiconPrior);
    var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
    var S1 = speaker(obj, lexiconName, priorProbs, speakerOptimality, sem_knowledge);
    observe(S1, utterance)
    return obj.shape == "novel_object" ? 1 : 0
  }})
}, 10000)

'
```



## Priors for speaker optimality

```{r FIXME}
semKnowPriors <- '
var data = dataFromR.data

var priorProbs = [.5,.5]

var familiars = levels(data, "familiar")

var model  = function(){

  var so_slope = uniformDrift({a: -2, b: 2, width: 0.2})
  var so_int = uniformDrift({a: -2, b: 2, width: 0.2})
  //var speakerOptimality = uniformDrift({a: -5, b: 5, width: 0.2})

  var sem_slope_global = uniformDrift({a: -2, b: 2, width: 0.2})
  var sem_int_global = uniformDrift({a: 0, b: 5, width: 0.2})

  var item_slope_sigma = uniformDrift({a: 0, b: 5, width: 0.2})
  // conceptually it might not make sense to have two sigmas, but maybe it does
  // intercept sigma probably will be smaller than slope sigma
  var item_int_sigma = uniformDrift({a: 0, b: 5, width: 0.2})
  
  foreach(function(cndtn){

    var conditionData = _.filter(data, {familiar: cndtn})
    
    var sem_slope_item = gaussianDrift({mu: sem_slope_global, sigma: item_slope_sigma, width: 0.5})
    var sem_int_item = gaussianDrift({mu: sem_int_global, sigma: item_int_sigma, width: 0.5})
    
    // var sem_slope = uniformDrift({a: -2, b: 2, width: 0.2})
    // var sem_int = uniformDrift({a: 0, b: 5, width: 0.2})

    foreach(function(row){

      var age = row.age

      //display(age)

      var sem_knowledge = logistic(sem_int_item + sem_slope_item * age)

      var speakerOptimality = so_int  + so_slope * age

      var modelPredictions = pragmaticListener({label: "novel_word"}, 
            priorProbs, speakerOptimality, sem_knowledge)
      // display(modelPredictions.score(row.correct))
      
      observe(modelPredictions, row.correct)
      
      query.add(["modelPrediction", cndtn, age], [age, Math.exp(modelPredictions.score(1))])

    }, conditionData)
    
    query.add(["parameter","items", cndtn], [sem_int_item, sem_slope_item])

  }, familiars)

  query.add(["parameter","parameters","speaker_optimality"], [so_int, so_slope])
  query.add(["parameter","parameters", "global_sem"], [sem_int_global, sem_slope_global])
  query.add(["parameter","sigma", "global_sem_sigmas"], [item_int_sigma, item_slope_sigma])
  
  return query 
}
'
```

## Priors for inferring semantic knowledge


```{r old}
semKnowPriors <- '

var logistic = function(x) {1 / (1 + Math.exp(-x))}

var levels = function(df, label){
  return _.uniq(_.map(df, label));
}

var data = dataFromR.data

var priorProbs = [.5,.5]

var familiars = levels(data, "familiar")

var discreteUniformBins = function(lower, upper, bin_width){
  _.range(lower, upper, bin_width)
}

var all_ages = sort(levels(data, "age"))

var model  = function(){

  var globalLineParameters = {
    intercept:  discreteUniformBins(0, 5, 2),
    slope: discreteUniformBins(-2, 2, 2)
  }

  var itemVariability = {
    intercept: discreteUniformBins(0.01, 5, 2),
    slope: discreteUniformBins(0.01, 5, 2)
  }
  // conceptually it might not make sense to have two sigmas, but maybe it does
  // intercept sigma probably will be smaller than slope sigma
  

    
  // display([
  //  globalLineParameters.intercept, itemVariability.intercept,
  //  globalLineParameters.slope, itemVariability.slope,
  //  itemLineParameters.intercept, itemLineParameters.slope
  // ])
  var output = map(function(globalLineIntercept){
    map(function(globalLineSlope){
      map(function(itemVariabilityIntercept){
          map(function(itemVariabilitySlope){
          
            var itemLineParameters = {
              intercept: discreteUniformBins(
                globalLineIntercept - 1*itemVariabilityIntercept,
                globalLineIntercept + 1*itemVariabilityIntercept,
                itemVariabilityIntercept
              ),
              slope: discreteUniformBins(
                globalLineSlope - 1*itemVariabilitySlope,
                globalLineSlope + 1*itemVariabilitySlope,
                itemVariabilitySlope
              )
            }
            
            map(function(itemLineIntercept){
                map(function(itemLineSlope){
                  map(function(age){
                    var sem_knowledge = logistic(itemLineIntercept + 
                      itemLineSlope * age)
                    // display(itemLineParameters.intercept + "+ " + itemLineParameters.slope + " X " + age + " =logistic= " + sem_knowledge)
                    var priorProbs =  [.5,.5]
                    var speakerOptimality = 1
                    
                    var modelPredictions = pragmaticListener({label: "novel_word"}, 
                            priorProbs, speakerOptimality, sem_knowledge)
                    var smk =  "semKnowledge_" + age
                    var mpa =  "modelPrediction_" + age
                    return {
                      global_intercept: globalLineIntercept,
                      global_slope: globalLineSlope,
                      sigma_intercept:itemVariabilityIntercept, 
                      sigma_slope:itemVariabilitySlope, 
                      item_intercept: itemLineIntercept,
                      item_slope: itemLineSlope,
                      age: age,
                      sem_knowledge : sem_knowledge,
                      L1 : Math.exp(modelPredictions.score(1))
                    }
                
                  }, all_ages)
    
              }, itemLineParameters.slope)
            }, itemLineParameters.intercept)
            
        }, itemVariability.slope)
      }, itemVariability.intercept)
    }, globalLineParameters.slope)
  }, globalLineParameters.intercept)
  
  _.flattenDeep(output)
  // return query
}
'
```


```{r}
me_model_data <- read_csv("../data/child_basic_me.csv")%>%
    filter(trial != "train1",
           trial != "train2")%>%
  mutate(age = age_num - min(age_num))

sem_know_model<- webppl(
  program_code = paste(rsaUtils, rsaModel, semKnowPriors , "model()", sep='\n'),
  data = list(data = me_model_data),
  data_var = "dataFromR",
  model_var = "model",
  #inference_opts = list(method = "enumerate")
)

```

# copied code 

=>
```{r}
save(sem_know_model, "parameter_enumeration_so1_flatPriors.RData")
load(file = "parameter_enumeration_so1_flatPriors.RData")# sem_know_model
```



```{r}
baseMeModel <- '

var sem_knowledge = 1

var priorProbs = [.5,.5]

var speakerOptimality = 1

var modelPredictions = pragmaticListener({label: "novel_word"}, priorProbs, speakerOptimality, sem_knowledge)

modelPredictions

'
```


```{r}
webppl(program_code = paste(rsaUtils, rsaModel, baseMeModel,sep='\n'))
```

# Inferring semantic knowledge
```{r}
semStr <- '
var data = dataFromR.data

var priorProbs = [.5,.5]

var familiars = levels(data, "familiar")

var model  = function(){

  var so_slope = uniformDrift({a: -2, b: 2, width: 0.2})
  var so_int = uniformDrift({a: -2, b: 2, width: 0.2})
  //var speakerOptimality = uniformDrift({a: -5, b: 5, width: 0.2})

  var sem_slope_global = uniformDrift({a: -2, b: 2, width: 0.2})
  var sem_int_global = uniformDrift({a: 0, b: 5, width: 0.2})

  var item_slope_sigma = uniformDrift({a: 0, b: 5, width: 0.2})
  // conceptually it might not make sense to have two sigmas, but maybe it does
  // intercept sigma probably will be smaller than slope sigma
  var item_int_sigma = uniformDrift({a: 0, b: 5, width: 0.2})
  
  foreach(function(cndtn){

    var conditionData = _.filter(data, {familiar: cndtn})
    
    var sem_slope_item = gaussianDrift({mu: sem_slope_global, sigma: item_slope_sigma, width: 0.5})
    var sem_int_item = gaussianDrift({mu: sem_int_global, sigma: item_int_sigma, width: 0.5})
    
    // var sem_slope = uniformDrift({a: -2, b: 2, width: 0.2})
    // var sem_int = uniformDrift({a: 0, b: 5, width: 0.2})

    foreach(function(row){

      var age = row.age

      //display(age)

      var sem_knowledge = logistic(sem_int_item + sem_slope_item * age)

      var speakerOptimality = so_int  + so_slope * age

      var modelPredictions = pragmaticListener({label: "novel_word"}, 
            priorProbs, speakerOptimality, sem_knowledge)
      // display(modelPredictions.score(row.correct))
      
      observe(modelPredictions, row.correct)
      
      query.add(["modelPrediction", cndtn, age], [age, Math.exp(modelPredictions.score(1))])

    }, conditionData)
    
    query.add(["parameter","items", cndtn], [sem_int_item, sem_slope_item])

  }, familiars)

  query.add(["parameter","parameters","speaker_optimality"], [so_int, so_slope])
  query.add(["parameter","parameters", "global_sem"], [sem_int_global, sem_slope_global])
  query.add(["parameter","sigma", "global_sem_sigmas"], [item_int_sigma, item_slope_sigma])
  
  return query 
}
'
```




```{r}
me_model_data <- read_csv("../data/child_basic_me.csv")%>%
    filter(trial != "train1",
           trial != "train2")%>%
  mutate(age = age_num - min(age_num))

sem_know_model<- webppl(
  program_code = paste(rsaUtils, rsaModel, semStr , sep='\n'),
  data = list(data = me_model_data),
  data_var = "dataFromR",
  model_var = "model",
  chains = 3,
  cores = 3,
  inference_opts = list(method = "incrementalMH", 
                        samples = 2000, 
                        burn = 1000,
                        verbose = T,
                        verboseLag = 500)
)

#saveRDS(sem_know_model, "../saves/sem_know_model.rds")
sem_know_model <- readRDS("../saves/sem_know_model.rds")
```
