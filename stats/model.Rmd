---
title: "Model"
author: "M. Bohn"
output: html_document
---

## Model utilities

```{r}
library(tidyverse)
library(rwebppl)
library(brms)
library(coda)
library(ggthemes)
library(readxl)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}


hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}

```

```{r rsaUtils}
rsaUtils <- '
var all_objects = [
{ shape: "novel_object"},  
{ shape: "familiar_object"}
]

var labels = ["novel_word","familiar_word"]


var lexicon1 = function(utterance, obj, sem_knowledge){
utterance.label == "novel_word" ? obj.shape == "novel_object" :
utterance.label == "familiar_word" ? flip(sem_knowledge) ? obj.shape == "familiar_object" :  obj.shape == "novel_object" : 
true
}

var lexicon2 = function(utterance, obj, sem_knowledge){
utterance.label == "novel_word" ? obj.shape == "familiar_object" :
utterance.label == "familiar_word" ? flip(sem_knowledge) ? obj.shape == "familiar_object" :  obj.shape == "novel_object" : 
true
}

var lexiconObjects = {
"novel_word = novel_object": {
novel_object: "novel_word", familiar_object: "familiar_word"
},
"novel_word = familiar_object": {
novel_object: "familiar_word", familiar_object: "familiar_word"
},
}

var lexiconObject = {
"novel_word = novel_object": lexicon1,
"novel_word = familiar_object" : lexicon2
}

var utterancePrior = function(){ return uniformDraw([ {label: "novel_word"}, {label: "familiar_word"}]) }

var LexiconPrior = Categorical({vs: ["novel_word = novel_object","novel_word = familiar_object" ], ps: [1, 1]})

var foreach = function(fn, lst) {
    var foreach_ = function(i) {
        if (i < lst.length) {
            fn(lst[i]);
            foreach_(i + 1);
        }
    };
    foreach_(0);
};

var logistic = function(x) {1 / (1 + Math.exp(-x))}

var levels = function(df, label){
  return _.uniq(_.map(df, label));
}
'
```

```{r rsa model}
rsaModel <- '
var literalListener = cache(function(utterance, priorProbs, sem_knowledge){
  Infer({method: "enumerate", model: function(){
    var lexiconName = sample(LexiconPrior); 
    var lexicon = lexiconObject[lexiconName];
    var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
    if ("label" in utterance) {
      var truthValue = lexicon(utterance, obj, sem_knowledge);
      condition(truthValue)
    }
    return obj.shape 
  }})
})

var speaker = cache(function(obj, lexiconName, priorProbs, speakerOptimality, sem_knowledge){
  Infer({method: "enumerate", model: function(){
    var utterance = utterancePrior();
    var L0 = literalListener(utterance, priorProbs, sem_knowledge);
    factor(speakerOptimality * L0.score(obj.shape))
    return utterance
  }})
})

var pragmaticListener = cache(function(utterance, priorProbs, speakerOptimality, sem_knowledge){
  Infer({method: "enumerate", model: function(){
    var lexiconName = sample(LexiconPrior);
    var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
    var S1 = speaker(obj, lexiconName, priorProbs, speakerOptimality, sem_knowledge);
    observe(S1, utterance)
    return obj.shape == "novel_object" ? 1 : 0
  }})
})

'
```


```{r}
baseMeModel <- '

var sem_knowledge = 1

var priorProbs = [.5,.5]

var speakerOptimality = 1

var modelPredictions = pragmaticListener({label: "novel_word"}, priorProbs, speakerOptimality,sem_knowledge)

modelPredictions

'
```


```{r}
webppl(program_code = paste(rsaUtils, rsaModel, baseMeModel,sep='\n'))
```

# Inferring semantic knowledge
```{r}
semStr <- '
var data = dataFromR.data

var familiars = levels(data, "familiar")

var model  = function(){

  var params = map(function(cndtn){

    var conditionData = _.filter(data, {condition: cndtn})
    
    var sem_slope = uniformDrift({a: -5, b: 5, width: 0.2})
    var sem_int = uniformDrift({a: 0, b: 5, width: 0.2})    
    
    foreach(function(row){

      var age = row.age

      var sem_knowledge = logistic(sem_int + sem_slope * age)

      var modelPredictions = pragmaticListener({label: "novel_word"}, priorProbs, speakerOptimality,sem_knowledge)
      
      observe(modelPredictions, row.correct)

    }, conditionData)

    return extend([
      {int: sem_int, slope: sem_slope, familiar: cndtn}
    ])
 
  }, familiars)

params

}
'
```

```{r}
me_model_data <- read_csv("../data/child_basic_me.csv")%>%
    filter(trial != "train1",
           trial != "train2")%>%
  mutate(age = age_num - min(age_num))


sem_know_model<- webppl(
  program_code = paste(rsaUtils, rsaModel, semStr , sep='\n'),
  data = list(data = me_model_data),
  data_var = "dataFromR",
  model_var = "model",
  chains = 4,
  cores = 4,
  inference_opts = list(method = "MCMC", samples = 5000, burn = 2000, verbose = T)
)
  
sem_know <- sem_know_model %>%
  select(value) %>%
  map_df(bind_rows)%>%
  rename(int = `0.int`,
         slope = `0.slope`,
         familiar = `0.familiar`)%>% 
  gather(parameter, value, -familiar)

sem_know_params <- sem_know %>%
  group_by(familiar,parameter)%>%
  summarise(mode = estimate_mode(value),
            uci = hdi_upper(value),
            lci = hdi_lower(value))
```

```{r}
ggplot(sem_know, aes(value))+
  geom_density()+
  xlab("Parameter")+
  facet_grid(parameter ~familiar)+
  theme_few()
```
## Plotting semantic knowledge
```{r}

aoa_ratings_all <- read_xlsx(path = "../data/words_aoa_ratings.xlsx", sheet = 1)

aoa_ratings <- aoa_ratings_all %>%
  filter(Word %in% sem_know_params$familiar )%>%
  mutate(mean_aoa = as.numeric(Rating.Mean),
         familiar = Word)%>%
  select(familiar,mean_aoa)

plot_sem_know <- sem_know_params%>%
  select(-uci,-lci)%>%
  spread(parameter, -familiar)%>%
  expand(familiar, slope, int,age = me_model_data$age)%>%
  mutate(sem_know = plogis(int + slope * age))%>%
  left_join(aoa_ratings)%>%
  ungroup()%>%
  mutate(familiar = fct_reorder(factor(familiar), mean_aoa))

ggplot(plot_sem_know, aes(x = age+2, y= sem_know, col = familiar))+
  geom_line(size = 1)+
  ylab("Semantic knowledge")+
  xlab("Age")+
  ylim(0,1)+
  theme_few()+
  scale_colour_viridis_d(name = "familiar object")
```


# Ignore: Model for ME Effect
```{r}
me_data <- read_csv("../data/child_basic_me.csv")%>%
    filter(trial != "train1",
           trial != "train2")%>%
  mutate(z_age = age_num - mean(age_num))

# me_model <- brm(correct ~ z_age + (1|subid) + (z_age | familiar),
#                 data = me_data,
#                 family = bernoulli(),
#                 control = list(adapt_delta = 0.95),
#                 sample_prior = F,
#                 save_all_pars = TRUE,
#                 iter = 2000)

saveRDS(me_model, "../saves/me_effect_model.rds")

me_model <- readRDS("../saves/me_effect_model.rds")

summary(me_model)

fixef <- as_tibble(fixef(me_model), rownames = "term")

ranef <-  ranef(me_model)

age_me_effect <- as_tibble(ranef$familiar, rownames = "familiar")%>%
  mutate(grand_intercept = fixef%>%filter(term=="Intercept")%>%pull(Estimate),
         grand_slope = fixef%>%filter(term=="z_age")%>%pull(Estimate))%>%
  group_by(familiar) %>%
  expand(Estimate.Intercept,Estimate.z_age,grand_intercept,grand_slope,z_age = me_data$age_num - mean(me_data$age_num), mean_age = mean(me_data$age_num))%>%
  mutate(me_effect = plogis(grand_intercept + Estimate.Intercept+(Estimate.z_age+grand_slope)*z_age), 
         age = z_age+mean_age)%>%
  select(familiar, me_effect, age)

```
