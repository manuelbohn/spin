---
title: "Model"
author: "M. Bohn"
output: html_document
---

## Model utilities

```{r}
library(tidyverse)
library(rwebppl)
library(brms)
library(coda)
library(ggthemes)
library(readxl)
library(ggpubr)
library(stringr)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}


hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}

me_data <- read_csv("../data/child_basic_me.csv")

```

```{r rsaUtils}
rsaUtils <- '
var all_objects = [
{ shape: "novel_object"},  
{ shape: "familiar_object"}
]

var labels = ["novel_word","familiar_word"]


var lexicon1 = function(utterance, obj, sem_knowledge){
utterance.label == "novel_word" ? obj.shape == "novel_object" :
utterance.label == "familiar_word" ? flip(sem_knowledge) ? obj.shape == "familiar_object" :  obj.shape == "novel_object" : 
true
}

var lexicon2 = function(utterance, obj, sem_knowledge){
utterance.label == "novel_word" ? obj.shape == "familiar_object" :
utterance.label == "familiar_word" ? flip(sem_knowledge) ? obj.shape == "familiar_object" :  obj.shape == "novel_object" : 
true
}

var lexiconObjects = {
"novel_word = novel_object": {
novel_object: "novel_word", familiar_object: "familiar_word"
},
"novel_word = familiar_object": {
novel_object: "familiar_word", familiar_object: "familiar_word"
},
}

var lexiconObject = {
"novel_word = novel_object": lexicon1,
"novel_word = familiar_object" : lexicon2
}

var utterancePrior = function(){ return uniformDraw([ {label: "novel_word"}, {label: "familiar_word"}]) }

var LexiconPrior = Categorical({vs: ["novel_word = novel_object","novel_word = familiar_object" ], ps: [1, 1]})

var foreach = function(fn, lst) {
    var foreach_ = function(i) {
        if (i < lst.length) {
            fn(lst[i]);
            foreach_(i + 1);
        }
    };
    foreach_(0);
};

var logistic = function(x) {1 / (1 + Math.exp(-x))}

var levels = function(df, label){
  return _.uniq(_.map(df, label));
}
'
```

```{r rsa model}
rsaModel <- '
var literalListener = cache(function(utterance, priorProbs, sem_knowledge){
  Infer({method: "enumerate", model: function(){
    var lexiconName = sample(LexiconPrior); 
    var lexicon = lexiconObject[lexiconName];
    var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
    if ("label" in utterance) {
      var truthValue = lexicon(utterance, obj, sem_knowledge);
      condition(truthValue)
    }
    return obj.shape 
  }})
}, 10000)

var speaker = cache(function(obj, lexiconName, priorProbs, speakerOptimality, sem_knowledge){
  Infer({method: "enumerate", model: function(){
    var utterance = utterancePrior();
    var L0 = literalListener(utterance, priorProbs, sem_knowledge);
    factor(speakerOptimality * L0.score(obj.shape))
    return utterance
  }})
}, 10000)

var pragmaticListener = cache(function(utterance, priorProbs, speakerOptimality, sem_knowledge){
  Infer({method: "enumerate", model: function(){
    var lexiconName = sample(LexiconPrior);
    var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
    var S1 = speaker(obj, lexiconName, priorProbs, speakerOptimality, sem_knowledge);
    observe(S1, utterance)
    return obj.shape == "novel_object" ? 1 : 0
  }})
}, 10000)

'
```


```{r}
baseMeModel <- '

var sem_knowledge = 1

var priorProbs = [.5,.5]

var speakerOptimality = 1

var modelPredictions = pragmaticListener({label: "novel_word"}, priorProbs, speakerOptimality, sem_knowledge)

modelPredictions

'
```


```{r}
webppl(program_code = paste(rsaUtils, rsaModel, baseMeModel,sep='\n'))
```

# Inferring semantic knowledge
```{r}
semStr <- '
var data = dataFromR.data

var priorProbs = [.5,.5]

var familiars = levels(data, "familiar")

var model  = function(){

  var so_slope = uniformDrift({a: -2, b: 2, width: 0.2})
  var so_int = uniformDrift({a: -2, b: 2, width: 0.2})
  //var speakerOptimality = uniformDrift({a: -5, b: 5, width: 0.2})

  var sem_slope_global = uniformDrift({a: -2, b: 2, width: 0.2})
  var sem_int_global = uniformDrift({a: 0, b: 5, width: 0.2})

  var item_slope_sigma = uniformDrift({a: 0, b: 5, width: 0.2})
  // conceptually it might not make sense to have two sigmas, but maybe it does
  // intercept sigma probably will be smaller than slope sigma
  var item_int_sigma = uniformDrift({a: 0, b: 5, width: 0.2})
  
  foreach(function(cndtn){

    var conditionData = _.filter(data, {familiar: cndtn})
    
    var sem_slope_item = gaussianDrift({mu: sem_slope_global, sigma: item_slope_sigma, width: 0.5})
    var sem_int_item = gaussianDrift({mu: sem_int_global, sigma: item_int_sigma, width: 0.5})
    
    // var sem_slope = uniformDrift({a: -2, b: 2, width: 0.2})
    // var sem_int = uniformDrift({a: 0, b: 5, width: 0.2})

    foreach(function(row){

      var age = row.age

      var sem_knowledge = logistic(sem_int_item + sem_slope_item * age)

      var speakerOptimality = so_int  + so_slope * age

      var modelPredictions = pragmaticListener({label: "novel_word"}, 
            priorProbs, speakerOptimality, sem_knowledge)
      // display(modelPredictions.score(row.correct))
      
      observe(modelPredictions, row.correct)
      
      query.add(["modelPrediction", cndtn], [age, Math.exp(modelPredictions.score(1))])

    }, conditionData)
    
    query.add(["parameter", cndtn], [sem_int_item, sem_slope_item])

  }, familiars)

  query.add(["parameter", "speaker_optimality"], [so_int, so_slope])
  query.add(["parameter", "global_sem"], [sem_int_global, sem_slope_global])
  query.add(["parameter", "global_sem_sigmas"], [item_int_sigma, item_slope_sigma])
  
  return query 
}
'
```




```{r}
# me_model_data <- read_csv("../data/child_basic_me.csv")%>%
#     filter(trial != "train1",
#            trial != "train2")%>%
#   mutate(age = age_num - min(age_num))

sem_know_model<- webppl(
  program_code = paste(rsaUtils, rsaModel, semStr , sep='\n'),
  data = list(data = me_model_data),
  data_var = "dataFromR",
  model_var = "model",
  chains = 1,
  cores = 1,
  inference_opts = list(method = "incrementalMH", 
                        samples = 10, 
                        burn = 5,
                        verbose = T)#,
                        #verboseLag = 500)
)

#saveRDS(sem_know_model, "../saves/sem_know_model.rds")
sem_know_model <- readRDS("../saves/sem_know_model.rds") %>%
  filter(Chain != 1)
```

```{r}

sem_know <- sem_know_model %>%
  filter(Parameter != "speaker_optimality") %>%
  mutate(Parameter = factor(Parameter)) %>%
  separate(value, into = c("intercept", "slope"), 
           sep = ", ") %>%
  mutate(intercept = as.numeric(str_remove_all(intercept, "[(c]")),
         slope = as.numeric(str_remove(slope, "[)]"))) %>%
  rename(item = Parameter) %>%
  gather(parameter, value, intercept, slope)
  

sem_know_params <- sem_know %>%
  group_by(item, parameter)%>%
  summarise(mode = estimate_mode(value),
            uci = hdi_upper(value),
            lci = hdi_lower(value))


speak_opt <- sem_know_model %>%
  filter(Parameter == "speaker_optimality") %>%
  separate(value, into = c("intercept", "slope"), 
           sep = ", ")%>%
  mutate(intercept = as.numeric(str_remove_all(intercept, "[(c]")),
         slope = as.numeric(str_remove(slope, "[)]"))) %>%
  rename(item = Parameter) %>%
  gather(parameter, value, intercept, slope)

```

```{r}
ggplot(sem_know, aes(x = value))+#, fill = factor(Chain)))+
  geom_density(alpha = 0.3)+
  xlab("Parameter")+
  facet_grid(parameter~item, scales = 'free')+
  theme_few()
```

```{r}
ggplot(speak_opt, aes(value))+
  geom_density()+
  xlab("Parameter")+
  facet_grid(~parameter, scales = 'free')+
  theme_few()
```

## Plotting semantic knowledge
```{r}
aoa_ratings_all <- read_xlsx(path = "../data/words_aoa_ratings.xlsx", sheet = 1)

aoa_ratings <- aoa_ratings_all %>%
  filter(Word %in% sem_know_params$item )%>%
  mutate(mean_aoa = as.numeric(Rating.Mean),
         item = Word)%>%
  select(item,mean_aoa)

plot_sem_know <- sem_know_params%>%
  select(-uci,-lci)%>%
  spread(parameter, -item) %>%
  left_join(expand.grid(
      age = unique(me_model_data$age),
      item = me_model_data$familiar), .) %>%
  mutate(sem_know = plogis(intercept + slope * age)) %>%
  left_join(aoa_ratings) %>%
  ungroup()%>%
  mutate(item = fct_reorder(factor(item), mean_aoa))

ggplot(plot_sem_know, aes(x = age+2, y= sem_know, col = item, group = item))+
  geom_line(size = 1)+
  ylab("Semantic knowledge")+
  xlab("Age")+
  ylim(0,1)+
  theme_few()+
  scale_colour_viridis_d(name = "familiar object")
```

# inverse predictions

```{r}
speak_opt_params <- speak_opt %>%
  group_by(parameter)%>%
  summarise(mode = estimate_mode(value),
            uci = hdi_upper(value),
            lci = hdi_lower(value))

inv_model_data <- sem_know_model %>%
  filter(Parameter != "speaker_optimality") %>%
  mutate(Parameter = factor(Parameter)) %>%
  separate(value, into = c("intercept", "slope"), 
           sep = ", ") %>%
  mutate(intercept = as.numeric(str_remove_all(intercept, "[(c]")),
         slope = as.numeric(str_remove(slope, "[)]"))) %>%
  rename(item = Parameter)%>%
  group_by(item)%>%
  summarise(sem_int = estimate_mode(intercept),
            sem_slope = estimate_mode(slope))%>%
  group_by(item)%>%
  expand(sem_int,sem_slope,age = me_model_data$age)%>%
  mutate(so_int = speak_opt_params%>%filter(parameter == "intercept")%>%pull(mode),
         so_slope = speak_opt_params%>%filter(parameter == "slope")%>%pull(mode))%>%
  mutate(speaker_optimality = so_int + so_slope * age,
         semantic_knowledge = plogis(sem_int + sem_slope * age))


```


```{r}
invPred <- '
var allData = dataFromR.data

var priorProbs = [.5,.5]

var output = map(function(row){

    var modelPredictions = pragmaticListener({label: "novel_word"}, priorProbs, row.speaker_optimality,row.semantic_knowledge)

    return extend([row.item + "/" + row.age, Math.exp(modelPredictions.score(1))])

}, allData)

output


'
```


```{r predictions pragmatic model ex 3 adults}
inv_model_pred<- webppl(
  program_code = paste(rsaUtils, rsaModel, invPred , sep='\n'),
  data =list(data = inv_model_data),
  data_var = "dataFromR"
)

#saveRDS(inv_model_pred, "../saves/inv_model_pred.rds")
#inv_model_pred <- readRDS("../saves/inv_model_pred.rds")

inv_predictions <- inv_model_pred %>%
  separate(`0`, into = c("item", "age"), sep="/")%>%
  mutate(age = as.numeric(age))%>%
  rename( me_effect = `1`)%>%
  left_join(aoa_ratings)%>%
  ungroup()%>%
  mutate(item = fct_reorder(factor(item), mean_aoa), 
         age = age + min(me_data$age_num))

inv_model_plot <- ggplot(inv_predictions, aes(x=age,y = me_effect, col = item))+
  geom_hline(yintercept = 0.5, lty=2)+
  geom_line(size = 1)+
  ggtitle("Inverse Model Predictions")+
  labs(x="Age",y="Proportion correct")+
  theme_few() +
  ylim(-0.05,1.05)+
  xlim(2,5)+
  guides(alpha = F)+ 
  scale_colour_viridis_d()

inv_model_plot
```


## For comparison: GLMM for ME effect and data
```{r}
me_data <- read_csv("../data/child_basic_me.csv")%>%
    filter(trial != "train1",
           trial != "train2")%>%
  mutate(z_age = age_num - mean(age_num))

# me_model <- brm(correct ~ z_age + (1|subid) + (z_age | familiar),
#                 data = me_data,
#                 family = bernoulli(),
#                 control = list(adapt_delta = 0.95),
#                 sample_prior = F,
#                 save_all_pars = TRUE,
#                 iter = 2000)

#saveRDS(me_model, "../saves/me_effect_model.rds")

me_model <- readRDS("../saves/me_effect_model.rds")

summary(me_model)

fixef <- as_tibble(fixef(me_model), rownames = "term")

ranef <-  ranef(me_model)

age_me_effect <- as_tibble(ranef$familiar, rownames = "familiar")%>%
  mutate(grand_intercept = fixef%>%filter(term=="Intercept")%>%pull(Estimate),
         grand_slope = fixef%>%filter(term=="z_age")%>%pull(Estimate))%>%
  group_by(familiar) %>%
  expand(Estimate.Intercept,Estimate.z_age,grand_intercept,grand_slope,z_age = me_data$age_num - mean(me_data$age_num), mean_age = mean(me_data$age_num))%>%
  mutate(me_effect = plogis(grand_intercept + Estimate.Intercept+(Estimate.z_age+grand_slope)*z_age), 
         age = z_age+mean_age,
         item = familiar)%>%
  select(item, me_effect, age)%>%
  left_join(aoa_ratings)%>%
  ungroup()%>%
  mutate(item = fct_reorder(factor(item), mean_aoa))


model_plot <- ggplot(age_me_effect, aes(x=age,y = me_effect, col = item))+
  geom_hline(yintercept = 0.5, lty=2)+
  geom_line(size = 1)+
  ggtitle("GLMM")+
  labs(x="Age",y="Proportion correct")+
  theme_few() +
  ylim(-0.05,1.05)+
  xlim(2,5)+
  guides(alpha = F)+ 
  scale_colour_viridis_d(name = "familiar object")


p2 <- read_csv("../data/child_basic_me.csv")%>%
  filter(trial != "train1",
         trial != "train2")%>%
  mutate(item = familiar)%>%
    left_join(aoa_ratings)%>%
  ungroup()%>%
  mutate(familiar = fct_reorder(factor(item), mean_aoa))

data_plot <- ggplot(data = p2, aes(x = age_num, y = correct, col = familiar, fill = familiar)) +
  geom_hline(yintercept = 0.5, lty=2)+
  geom_jitter(width = 0, height = 0.05, alpha = .6)+
  geom_smooth(method = "loess", se = F, alpha = .5, span = 2)+
  labs(x="Age",y="Mutual Exclusivity effect")+
  #facet_grid(~familiar)+
  ggtitle("Data")+
  theme_few() +
  ylim(-0.05,1.05)+
  xlim(2,5)+
  guides(alpha = F)+ 
  scale_colour_viridis_d(name = "familiar object")+
  scale_fill_viridis_d(name = "familiar object")
data_plot
```

```{r}
ggarrange(data_plot,inv_model_plot,model_plot, common.legend = T, legend = "right", nrow = 1, ncol = 3)
```

#### WORK IN PROGRESS: nesting within participant

to do:
- bookkeeping: index correct participant/item variables at relevant part of code
- inference: try HMC, variational

```{r work in progress}
semStr <- '
var data = dataFromR.data

var priorProbs = [.5,.5]

var familiars = levels(data, "familiar")

var model  = function(){

  // global parameters
  var so_slope = uniformDrift({a: -2, b: 2, width: 0.2})
  var so_int = uniformDrift({a: -2, b: 2, width: 0.2})

  var sem_slope_global = uniformDrift({a: -2, b: 2, width: 0.2})
  var sem_int_global = uniformDrift({a: 0, b: 5, width: 0.2})

  var item_slope_sigma = uniformDrift({a: 0, b: 5, width: 0.2})
  var item_int_sigma = uniformDrift({a: 0, b: 5, width: 0.2})
  
  var participant_age_adjust = gaussianDrift({mu: 0, sigma: 1, width: 0.2})
  
  var sem_slope_item = repeat(familiars.length, function(){
    gaussianDrift({mu: sem_slope_global, sigma: item_slope_sigma, width: 0.5} )
  })
  
  var sem_int_item = gaussianDrift({mu: sem_int_global, 
        sigma: item_int_sigma, width: 0.5})
      
  foreach(function(cndtn){

    var conditionData = _.filter(data, {familiar: cndtn})
    
    foreach(function(row){

      var age = row.age

      var sem_knowledge = logistic(sem_int_item + sem_slope_item * age)

      var speakerOptimality = so_int  + so_slope * age

      var modelPredictions = pragmaticListener({label: "novel_word"}, 
            priorProbs, speakerOptimality, sem_knowledge)
      // display(modelPredictions.score(row.correct))
      
      observe(modelPredictions, row.correct)
      
      query.add(["modelPrediction", cndtn], [age, Math.exp(modelPredictions.score(1))])

    }, conditionData)
    
    query.add(["parameter", cndtn], [sem_int_item, sem_slope_item])

  }, familiars)

  query.add(["parameter", "speaker_optimality"], [so_int, so_slope])
  query.add(["parameter", "global_sem"], [sem_int_global, sem_slope_global])
  query.add(["parameter", "global_sem_sigmas"], [item_int_sigma, item_slope_sigma])
  
  return query 
}
'
```
